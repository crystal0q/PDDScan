# -*- coding: utf-8 -*-
"""
ä¸€é”®æµæ°´çº¿ï¼š
1) æŠ“æ•°ï¼ˆæ¯è´¦å·åªæŸ¥ä¸€é¡µÃ—100æ¡ï¼‰-> output/pdd_goods_realtime.xlsx
2) ä»·æ ¼æ¯”å¯¹ï¼ˆä½äºæ§ä»·ï¼‰        -> output/filtered_result.xlsx
3) æ¸…æ´—ï¼ˆå·®é¢æ¯”>50%å‰”é™¤ + å»é‡) -> è¦†å†™ output/filtered_result.xlsx
"""
import os
import datetime
import re
import time
import random
import hashlib
import requests
import pandas as pd
import os, sys
BASE = getattr(sys, '_MEIPASS', os.path.abspath(os.path.dirname(__file__)))
PRICE_PATH = os.path.join(BASE, 'price.xlsx')
# =============ã€A. æŠ“æ•°ï¼šä¸€æ¬¡100æ¡ã€‘=========================================
ACCOUNTS = [
    {"name": "kk",  "CLIENT_ID": "98a8c70b50294461bd62930e9d9686cc",
     "CLIENT_SECRET": "f7bd3900d6def8e9d12dd198cb7838eedb1d527b", "PID": "43512226_310483284"},
    {"name": "zzz", "CLIENT_ID": "dc2351f5456c44f38d18cb0c2d58c519",
     "CLIENT_SECRET": "d25a5cb402973c2582e8d5ee09895e92535f399d", "PID": "43527621_310596310"},
]
RAW_KEYWORDS = [
    "é‡‘å…¸ ç‰›å¥¶","å®‰æ…•å¸Œ é…¸å¥¶","çº¯ç‰›å¥¶ ä¼Šåˆ©","é«˜é’™å¥¶ ä¼Šåˆ©","æ—©é¤å¥¶ è‡»æµ“",
    "ä¼˜é…¸ä¹³","èˆ’åŒ–","QQæ˜Ÿ","è°·ç²’å¤š","ç”œå‘³å¥¶","ç•…æ„","ä¼Šåˆ» æ¤é€‰"
]
# RAW_KEYWORDS = [
#     "é‡‘å…¸","å®‰æ…•å¸Œ é…¸å¥¶"
# ]
def _clean_kw(s:str)->str:
    s=str(s).strip()
    s=re.sub(r"[ã€‚ï¼ï¼Ÿï¼›ï¼Œã€]", " ", s)
    s=re.sub(r"\s+", " ", s)
    return s
KEYWORDS=[_clean_kw(k) for k in RAW_KEYWORDS if k and k.strip()]

PDD_API_URL="https://gw-api.pinduoduo.com/api/router"
CUSTOM_PARAMETERS='{"uid":"demo","source":"test"}'
OUTPUT_DIR="output"
GOODS_FILE=os.path.join(OUTPUT_DIR,"pdd_goods_realtime.xlsx")
os.makedirs(OUTPUT_DIR, exist_ok=True)

PAGE=1
PAGE_SIZE=100

def _sign(params:dict, secret:str)->str:
    items=sorted(params.items())
    raw=secret + "".join(f"{k}{v}" for k,v in items) + secret
    return hashlib.md5(raw.encode("utf-8")).hexdigest().upper()

def _search_goods(account:dict, keyword:str, page:int=PAGE, page_size:int=PAGE_SIZE)->dict:
    params={
        "type":"pdd.ddk.goods.search",
        "client_id":account["CLIENT_ID"],
        "timestamp":int(time.time()),
        "data_type":"JSON",
        "keyword":keyword,
        "pid":account["PID"],
        "custom_parameters":CUSTOM_PARAMETERS,
        "page":page,
        "page_size":page_size,
        # "sort_type":0,  # å¦‚éœ€å›ºå®šæ’åºå¯å¯ç”¨
    }
    params["sign"]=_sign(params, account["CLIENT_SECRET"])
    r=requests.post(PDD_API_URL, data=params, timeout=20)
    return r.json()

def _append_goods_rows(rows:list):
    if not rows:
        return
    df_new=pd.DataFrame(rows)
    if not os.path.exists(GOODS_FILE):
        df_new.to_excel(GOODS_FILE, index=False)
        print(f"ğŸ’¾ åˆ›å»º: {GOODS_FILE}ï¼ˆ{len(df_new)}æ¡ï¼‰")
        return
    df_old=pd.read_excel(GOODS_FILE)
    df_all=pd.concat([df_old, df_new], ignore_index=True)
    df_all.drop_duplicates(subset=["goods_id"], inplace=True)
    df_all.to_excel(GOODS_FILE, index=False)
    print(f"ğŸ“ˆ è¿½åŠ  {len(rows)} æ¡ï¼Œç°å…± {len(df_all)} æ¡")

def run_fetch():
    print("â–¶ A. æŠ“æ•°ï¼ˆè½®è¯¢è´¦å·ï¼šæ¯å…³é”®è¯åªç”¨ä¸€ä¸ªè´¦å·ï¼›é™æµè´¦å·å³æ—¶ç¦ç”¨ï¼‰")
    # å¯ç”¨çŠ¶æ€è¡¨
    account_enabled = {a["name"]: True for a in ACCOUNTS}
    # å½“å‰è½®è¯¢æŒ‡é’ˆ
    idx = 0  # æŒ‡å‘ä¸‹ä¸€ä¸ªä¼˜å…ˆå°è¯•çš„è´¦å·ä¸‹æ ‡
    n_accounts = len(ACCOUNTS)

    seen = set()   # å·²è§ goods_id
    total = 0

    def next_enabled(start_idx):
        """ä» start_idx èµ·å‘å‰æ‰¾ç¬¬ä¸€ä¸ªå¯ç”¨è´¦å·ï¼›è‹¥å…¨ä¸å¯ç”¨è¿”å› None"""
        if n_accounts == 0:
            return None
        for step in range(n_accounts):
            j = (start_idx + step) % n_accounts
            if account_enabled.get(ACCOUNTS[j]["name"], False):
                return j
        return None

    for kw in KEYWORDS:
        print(f"\nğŸ” å…³é”®è¯ï¼š{kw}")

        # æ‰¾åˆ°ä¸€ä¸ªå¯ç”¨è´¦å·æ¥å¤„ç†æœ¬å…³é”®è¯
        j = next_enabled(idx)
        if j is None:
            print("â›” æ‰€æœ‰è´¦å·å‡ä¸å¯ç”¨ï¼Œæå‰ç»“æŸæŠ“æ•°ã€‚")
            break

        tried = 0
        kw_new = 0
        success = False

        while tried < n_accounts:
            acc = ACCOUNTS[j]
            if not account_enabled.get(acc["name"], True):
                tried += 1
                j = (j + 1) % n_accounts
                continue

            # è½»å¾®éšæœºå»¶è¿Ÿï¼Œé™ä½è§¦å‘ç‡
            time.sleep(random.uniform(1.5, 3.5))
            print(f"â†’ ä½¿ç”¨è´¦å·æŸ¥è¯¢ 1 é¡µ Ã— {PAGE_SIZE} æ¡")

            try:
                res = _search_goods(acc, kw, page=PAGE, page_size=PAGE_SIZE)
            except Exception as e:
                print(f"âŒ {acc['name']} è¯·æ±‚å¼‚å¸¸ï¼š{e}")
                tried += 1
                j = (j + 1) % n_accounts
                continue

            if "error_response" in res:
                err = res["error_response"]
                sub = err.get("sub_code")
                print(f"âš ï¸ {acc['name']} æ¥å£å¼‚å¸¸ï¼š{err}")
                if sub == "40009":
                    # å³æ—¶ç¦ç”¨æœ¬è´¦å·ï¼Œæ¢ä¸‹ä¸€ä¸ªè´¦å·ç»§ç»­å°è¯•æœ¬å…³é”®è¯
                    account_enabled[acc["name"]] = False
                    print(f"ğŸš« è´¦å·å·²è¢«é™æµï¼Œæ ‡è®°ä¸ºä¸å¯ç”¨ã€‚")
                tried += 1
                j = (j + 1) % n_accounts
                continue

            goods = (res.get("goods_search_response", {}) or {}).get("goods_list", []) or []
            batch = []
            for g in goods:
                gid = str(g.get("goods_id"))
                if gid in seen:
                    continue
                seen.add(gid)
                batch.append({
                    "keyword": kw,
                    "account": acc["name"],
                    "goods_id": gid,
                    "goods_name": (g.get("goods_name") or "")[:120],
                    "price": (g.get("min_group_price") or 0) / 100,
                    "mall_id": g.get("mall_id"),
                })

            if batch:
                _append_goods_rows(batch)
                total += len(batch)
                kw_new += len(batch)
                print(f"âœ… å…³é”®è¯ã€{kw}ã€ç”±è´¦å·æ–°å¢ {len(batch)} æ¡")
            else:
                print(f"â†ªï¸ è´¦å·æœ¬æ¬¡æ— æ–°å¢")

            success = True
            break  # æœ¬å…³é”®è¯å·²ç”±æŸè´¦å·å®Œæˆï¼Œè·³å‡º while

        if not success:
            print(f"â— å…³é”®è¯ã€{kw}ã€æœªèƒ½æˆåŠŸæŸ¥è¯¢ï¼ˆè´¦å·éƒ½ä¸å¯ç”¨æˆ–å¼‚å¸¸ï¼‰ã€‚")

        # å°†è½®è¯¢æŒ‡é’ˆæŒªåˆ°â€œä¸‹ä¸€ä¸ªè´¦å·â€ï¼Œç”¨äºåˆ†é…ä¸‹ä¸€ä¸ªå…³é”®è¯
        j2 = next_enabled((idx + 1) % n_accounts)
        idx = j2 if j2 is not None else idx  # è‹¥å…¨ä¸å¯ç”¨å°±ä¿æŒä¸åŠ¨

        print(f"ğŸ å…³é”®è¯å®Œæˆï¼šæ–°å¢ {kw_new} æ¡")

    print(f"\nğŸ“ æŠ“æ•°å®Œæˆï¼Œç´¯è®¡æ–°å¢ {total} æ¡ â†’ {GOODS_FILE}")

# =============ã€B. æ¯”ä»·ï¼šç”Ÿæˆä½äºæ§ä»·æ¸…å•ã€‘===============================
PRICE_FILE="price.xlsx"   # sheet: ç”µå•†æ§ä»·
RESULT_FILE=os.path.join(OUTPUT_DIR, "filtered_result.xlsx")

def _extract_pack_count(name:str)->int:
    text=str(name); counts=[]
    for a,b,unit in re.findall(r'(\d+)\s*[xÃ—X]\s*(\d+)\s*(ç®±|æ)', text):
        try: counts.append(int(a)*int(b))
        except: pass
    for unit in ['ç®±','æ']:
        try:
            found=re.findall(r'(?<!\d)(\d+)\s*'+unit, text)
            counts.extend(int(n) for n in found)
        except: pass
    return max(1, min(counts)) if counts else 1

def _is_expiring(name:str)->bool:
    for m in re.findall(r'(\d{1,2})æœˆ', str(name)):
        try:
            if int(m)<=7: return True
        except: pass
    return False

def _extract_primary_size(text:str):
    if text is None: return (None,None)
    s=str(text)
    m=re.search(r'(\d+(?:\.\d+)?)\s*(ml|mL|ML|l|L|g|G)', s)
    if not m: return (None,None)
    val=float(m.group(1)); unit=m.group(2).lower()
    if unit in ('l',): return (val*1000.0, 'ml')
    elif unit in ('ml',): return (val, 'ml')
    else: return (val, 'g')

def _choose_best_by_spec(matched_df:pd.DataFrame, goods_name:str)->pd.Series:
    gv, gu = _extract_primary_size(goods_name)
    if gv is None or gu is None or "è§„æ ¼" not in matched_df.columns:
        return matched_df.iloc[0]
    tmp=matched_df.copy()
    spec_vals=[]; spec_units=[]
    for x in tmp["è§„æ ¼"] if "è§„æ ¼" in tmp.columns else [None]*len(tmp):
        v,u=_extract_primary_size(x); spec_vals.append(v); spec_units.append(u)
    tmp["_spec_val"]=spec_vals; tmp["_spec_unit"]=spec_units
    same_unit = tmp["_spec_unit"]==gu
    if same_unit.any():
        sub=tmp[same_unit].copy()
        sub["_spec_diff"]=(sub["_spec_val"]-gv).abs()
        sub=sub.sort_values(["_spec_diff"], kind="mergesort")
        return sub.iloc[0]
    return matched_df.iloc[0]

def run_compare():
    print("\nâ–¶ B. ä»·æ ¼æ¯”å¯¹ï¼ˆä½äºæ§ä»·ï¼‰")
    if not os.path.exists(PRICE_FILE):
        raise FileNotFoundError(f"æ§ä»·æ–‡ä»¶ä¸å­˜åœ¨ï¼š{PRICE_FILE}")
    if not os.path.exists(GOODS_FILE):
        raise FileNotFoundError(f"å•†å“æ–‡ä»¶ä¸å­˜åœ¨ï¼š{GOODS_FILE}")

    df_price=pd.read_excel(PRICE_FILE, sheet_name="ç”µå•†æ§ä»·")
    df_goods=pd.read_excel(GOODS_FILE)

    # ç»Ÿä¸€åˆ—å
    rename_map={"å•†å“åç§°":"goods_name","å•†å“å":"goods_name","goods_name":"goods_name",
                "å•†å“ID":"goods_id","goodsId":"goods_id",
                "ä»·æ ¼":"price","å½“å‰å”®ä»·":"price","mall_id":"mall_id"}
    for old,new in rename_map.items():
        if old in df_goods.columns and new not in df_goods.columns:
            df_goods.rename(columns={old:new}, inplace=True)

    # æ¸…æ´—æ§ä»·
    for col in ["ä¿ƒé”€æŒ‡å¼•ä»·","æ•ˆæœŸäº§å“æ§ä»·ï¼ˆå•æï¼‰"]:
        if col in df_price.columns:
            df_price[col]=df_price[col].astype(str).apply(
                lambda x: float(re.sub(r"[^\d.]","",x)) if re.search(r"\d",x) else None
            )
    for col in ["å“ç±»","å“é¡¹åç§°","äº§å“ç®€ç§°"]:
        if col not in df_price.columns: df_price[col]=""

    ban_keywords=["è’™ç‰›","æ–°å¸Œæœ›","è®¤å…»"]

    results=[]
    for idx,row in df_goods.iterrows():
        try:
            name=str(row.get("goods_name","")).strip()
            price=float(row.get("price",0))
        except Exception as e:
            print(f"âš ï¸ ç¬¬{idx}è¡Œè¯»å–å¼‚å¸¸ï¼š{e}"); continue
        if any(k in name for k in ban_keywords):
            continue
        matched=df_price[
            (df_price["å“é¡¹åç§°"].apply(lambda x: str(x) in name if not pd.isna(x) else False)) |
            (df_price["äº§å“ç®€ç§°"].apply(lambda x: str(x) in name if not pd.isna(x) else False))
            ]
        if matched.empty: continue

        p=_choose_best_by_spec(matched, name)
        exp=_is_expiring(name)
        compare_type="æ•ˆæœŸæ§ä»·" if exp else "ä¿ƒé”€æŒ‡å¼•ä»·"
        base_col='æ•ˆæœŸäº§å“æ§ä»·ï¼ˆå•æï¼‰' if exp else 'ä¿ƒé”€æŒ‡å¼•ä»·'
        base=float(p.get(base_col,0) or 0)

        pack=_extract_pack_count(name)
        compare_price=base*pack

        try:
            if float(price) < float(compare_price):
                diff=compare_price-price
                diff_ratio=(diff/compare_price*100) if compare_price!=0 else 0
                results.append({
                    "mall_id": row.get("mall_id",""),
                    "goods_id": row.get("goods_id",""),
                    "å•†å“åç§°": name,
                    "å“ç±»": p.get("å“ç±»",""),
                    "å“é¡¹åç§°": p.get("å“é¡¹åç§°",""),
                    "è§„æ ¼": p.get("è§„æ ¼","") if "è§„æ ¼" in p else "",
                    "å½“å‰å”®ä»·": round(price,2),
                    "æ¯”å¯¹ç±»å‹": compare_type,
                    "å•ææ§ä»·": round(base,2),
                    "å€æ•°": pack,
                    "è°ƒæ•´åæ§ä»·": round(compare_price,2),
                    "å·®é¢": round(diff,2),
                    "å·®é¢æ¯”": f"{diff_ratio:.1f}%",
                    "æ˜¯å¦æ•ˆæœŸå•†å“": "æ˜¯" if exp else "å¦",
                    "é“¾æ¥": f"https://mobile.yangkeduo.com/goods.html?goods_id={row.get('goods_id','')}"
                })
        except Exception as e:
            print(f"âš ï¸ æ¯”è¾ƒæ—¶å‡ºé”™ï¼š{e}")
            continue

    # å®‰å…¨åˆ›å»ºç›®å½•
    dir_name=os.path.dirname(RESULT_FILE)
    if dir_name: os.makedirs(dir_name, exist_ok=True)

    if not results:
        print("âš ï¸ æ²¡æœ‰ä½äºæ§ä»·çš„å•†å“ã€‚")
        # ä»ç„¶å†™ä¸€ä¸ªç©ºè¡¨ï¼Œä¾¿äºåç»­æ¸…æ´—æ­¥éª¤ç»Ÿä¸€å¤„ç†
        pd.DataFrame(columns=[
            "mall_id","goods_id","å•†å“åç§°","å“ç±»","å“é¡¹åç§°","è§„æ ¼","å½“å‰å”®ä»·",
            "æ¯”å¯¹ç±»å‹","å•ææ§ä»·","å€æ•°","è°ƒæ•´åæ§ä»·","å·®é¢","å·®é¢æ¯”","æ˜¯å¦æ•ˆæœŸå•†å“","é“¾æ¥"
        ]).to_excel(RESULT_FILE, index=False)
    else:
        df_res=pd.DataFrame(results)
        with pd.ExcelWriter(RESULT_FILE, engine="openpyxl") as w:
            df_res.to_excel(w, index=False, sheet_name="ç»“æœ")
        print(f"âœ… æ¯”ä»·å®Œæˆï¼š{len(df_res)} æ¡ â†’ {RESULT_FILE}")

# =============ã€C. æ¸…æ´—ï¼šå·®é¢æ¯”>50%å‰”é™¤ + å»é‡ã€‘=========================
def run_cleanup():
    print("\nâ–¶ C. æ¸…æ´—")
    if not os.path.exists(RESULT_FILE):
        print("âš ï¸ æœªæ‰¾åˆ°æ¯”å¯¹ç»“æœï¼Œè·³è¿‡æ¸…æ´—")
        return

    df = pd.read_excel(RESULT_FILE)
    print(f"åŸå§‹ï¼š{len(df)} æ¡")

    # â‘  å»é‡ï¼ˆæŒ‰ goods_idï¼‰
    if "goods_id" in df.columns:
        before = len(df)
        df = df.drop_duplicates(subset=["goods_id"])
        print(f"å»é‡ï¼šç§»é™¤ {before - len(df)} æ¡ï¼Œå½“å‰ {len(df)} æ¡")

    # â‘¡ å»æ‰ å·®é¢ < 0
    if "å·®é¢" in df.columns:
        df["å·®é¢"] = pd.to_numeric(df["å·®é¢"], errors="coerce")
        before = len(df)
        df = df[df["å·®é¢"] >= 0]
        print(f"å·®é¢<0ï¼šç§»é™¤ {before - len(df)} æ¡ï¼Œå½“å‰ {len(df)} æ¡")
    else:
        print("âš ï¸ ç¼ºå°‘â€œå·®é¢â€åˆ—ï¼Œè·³è¿‡å·®é¢<0è¿‡æ»¤")

    # â‘¢ å»æ‰ æŒ‡å®šå“ç±» ä¸” å•†å“åç§°åŒ…å«â€œä¼Šåˆ©â€
    target_categories = ["çº¯å¥¶", "åŠŸèƒ½å¥¶", "æ—©é¤å¥¶", "è‡»æµ“", "ç”œå‘³å¥¶", "è‰åŸé…¸å¥¶", "èŠ±è‰²å¥¶"]
    if ("å“ç±»" in df.columns) and ("å•†å“åç§°" in df.columns):
        # æ³¨æ„ï¼šè¿™é‡Œæ˜¯â€œåŒ…å«ä¼Šåˆ©â€çš„å‰”é™¤ï¼ˆä¸ä½ è¿™æ¬¡æè¿°ä¸€è‡´ï¼‰
        mask = df["å“ç±»"].isin(target_categories) & (~df["å•†å“åç§°"].astype(str).str.contains("ä¼Šåˆ©", na=False))
        removed = int(mask.sum())
        df = df[~mask]
        print(f"æŒ‡å®šå“ç±»ä¸”å«â€œä¼Šåˆ©â€ï¼šç§»é™¤ {removed} æ¡ï¼Œå½“å‰ {len(df)} æ¡")
    else:
        print("âš ï¸ ç¼ºå°‘â€œå“ç±»â€æˆ–â€œå•†å“åç§°â€åˆ—ï¼Œè·³è¿‡è¯¥è§„åˆ™")

    # â‘£ å»æ‰ å·®é¢æ¯” > 50%
    if "å·®é¢æ¯”" in df.columns:
        df["å·®é¢æ¯”æ•°å€¼"] = pd.to_numeric(
            df["å·®é¢æ¯”"].astype(str).str.replace("%", "", regex=False),
            errors="coerce"
        )
        before = len(df)
        df = df[df["å·®é¢æ¯”æ•°å€¼"] <= 50]
        removed = before - len(df)
        df.drop(columns=["å·®é¢æ¯”æ•°å€¼"], inplace=True)
        print(f"å·®é¢æ¯”>50%ï¼šç§»é™¤ {removed} æ¡ï¼Œå½“å‰ {len(df)} æ¡")
    else:
        print("âš ï¸ ç¼ºå°‘â€œå·®é¢æ¯”â€åˆ—ï¼Œè·³è¿‡å·®é¢æ¯”è¿‡æ»¤")
        # === ğŸ†• è¡¨å¤´é‡å‘½å ===
    df.rename(columns={
        "å•†å“åç§°": "ä¹°è´§äº§å“åç§°",
        "é“¾æ¥": "ä¹°è´§é“¾æ¥",
        "å½“å‰å”®ä»·": "ä¹°è´§ä»·æ ¼ï¼ˆå…ƒ/ä»¶ï¼‰"
    }, inplace=True)

    # === ğŸ†• åˆ é™¤ä¸éœ€è¦çš„åˆ— mall_id	goods_id æ¯”å¯¹ç±»å‹	å•ææ§ä»·	å€æ•°	è°ƒæ•´åæ§ä»·	å·®é¢	å·®é¢æ¯”	æ˜¯å¦æ•ˆæœŸå•†å“===
    drop_cols = [
        "mall_id", "goods_id", "æ¯”å¯¹ç±»å‹", "å•ææ§ä»·", "å€æ•°", "è°ƒæ•´åæ§ä»·", "å·®é¢", "å·®é¢æ¯”", "æ˜¯å¦æ•ˆæœŸå•†å“"
    ]
    df.drop(columns=drop_cols, inplace=True, errors='ignore')

    # === ğŸ†• å¢åŠ â€œå¹³å°åç§°â€åˆ— å“ç±»	å“é¡¹åç§°	è§„æ ¼ ===
    df["å¹³å°åç§°"] = "æ‹¼å¤šå¤š"
    df["æ‰¹æ¬¡åé¦ˆæ—¥æœŸ"] = datetime.date.today().strftime("%Y-%m-%d")
    desired_order = [
        "å¹³å°åç§°", "ä¹°è´§é“¾æ¥", "æ‰¹æ¬¡åé¦ˆæ—¥æœŸ", "ä¹°è´§äº§å“åç§°", "å“ç±»", "å“é¡¹åç§°", "è§„æ ¼", "ä¹°è´§ä»·æ ¼ï¼ˆå…ƒ/ä»¶ï¼‰"
    ]
    # å†™å›æ–‡ä»¶
    df.to_excel(RESULT_FILE, index=False)
    print(f"ğŸ“„ æ¸…æ´—å®Œæˆå¹¶ä¿®æ”¹è¡¨å¤´ï¼Œå·²è¦†å†™ï¼š{RESULT_FILE}")


    # å†™å›
    df.to_excel(RESULT_FILE, index=False)
    print(f"ğŸ“„ æ¸…æ´—å®Œæˆï¼Œå·²è¦†å†™ï¼š{RESULT_FILE}")


# =============ã€å·¥å…·å‡½æ•°ï¼šæ˜¯å¦æ¸…ç©ºæ—§æ•°æ®ã€‘=========================

def ask_clear_raw_data():  # ğŸŸ¢ æ–°å¢
    """è¯¢é—®æ˜¯å¦æ¸…ç©º output/pdd_goods_realtime.xlsx"""
    if os.path.exists(GOODS_FILE):
        ans = input(f"æ˜¯å¦æ¸…ç©ºåŸå§‹æ•°æ®æ–‡ä»¶ {GOODS_FILE}? (y/N): ").strip().lower()
        if ans == "y":
            os.remove(GOODS_FILE)
            print("ğŸ§¹ å·²æ¸…ç©ºæ—§çš„æŠ“å–æ•°æ®æ–‡ä»¶ã€‚")
        else:
            print("âœ… ä¿ç•™ç°æœ‰æŠ“å–æ•°æ®ã€‚")
    else:
        print("â„¹ï¸ å½“å‰ä¸å­˜åœ¨æ—§çš„æŠ“å–æ–‡ä»¶ï¼Œæ— éœ€æ¸…ç†ã€‚")

# =============ã€Main ä¸»æµç¨‹ã€‘========================================

if __name__ == "__main__":
    ask_clear_raw_data()  # ğŸŸ¢ æ–°å¢ï¼šè¿è¡Œå‰è¯¢é—®æ˜¯å¦æ¸…ç©ºæ—§æ–‡ä»¶
    run_fetch()           # A. æŠ“æ•°
    run_compare()         # B. æ¯”å¯¹
    run_cleanup()         # C. æ¸…æ´—
    print("\nğŸ‰ å…¨æµç¨‹å®Œæˆ")

